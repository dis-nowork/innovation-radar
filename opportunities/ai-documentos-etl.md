# ğŸ“„ AI/Documentos & ETL

Processamento de documentos, extraÃ§Ã£o de dados, pipelines de transformaÃ§Ã£o com AI.

### [docling-project/docling](https://github.com/docling-project/docling) â­ 51.8k | ğŸ¯ğŸ’¸âš¡ğŸ’
**Problema:** Empresas gastam centenas de horas/ano convertendo PDFs, DOCXs, slides em dados estruturados. Ferramentas pagas (Adobe Acrobat Pro, AWS Textract) sÃ£o caras e limitadas por formato.
**SoluÃ§Ã£o:** Parser universal open-source que converte PDF, DOCX, PPTX, XLSX, HTML, imagens e atÃ© Ã¡udio para formatos gen AI-ready (Markdown, JSON). Suporte a OCR, tabelas, fÃ³rmulas, layout avanÃ§ado. Roda 100% local.
**Por que Ã© 5-10x melhor:**
- ğŸ¯ **Problema real:** Todo workflow de RAG/AI comeÃ§a com "parse o documento" â€” docling Ã© a fundaÃ§Ã£o
- ğŸ’¸ **Custo:** $0 vs AWS Textract ($1.50/1000 pÃ¡ginas) ou Adobe ($240/ano)
- âš¡ **Velocidade:** `pip install docling` + 3 linhas de Python = conversÃ£o funcionando
- ğŸ’ **Qualidade:** Entende layout, tabelas, fÃ³rmulas â€” nÃ£o apenas "extrai texto bruto"
**TAM:** $4B+ (document processing market, crescendo 15% ao ano)
**Modelo de negÃ³cio:** Enterprise support, cloud hosted, integraÃ§Ã£o com plataformas de AI
**EsforÃ§o:** Baixo â€” jÃ¡ Ã© production-ready, integraÃ§Ãµes com LangChain/LlamaIndex/CrewAI prontas
**CombinaÃ§Ãµes:** Docling + Unstract (#94) + CocoIndex (#95) = pipeline completo docâ†’estruturadoâ†’vector DB

---

### [Zipstack/unstract](https://github.com/Zipstack/unstract) â­ 6.1k | ğŸ¯âš¡ğŸš€ğŸ’¸
**Problema:** Empresas recebem milhares de documentos nÃ£o-estruturados (faturas, contratos, relatÃ³rios) que precisam virar dados estruturados. Hoje Ã© manual ou requer devs caros.
**SoluÃ§Ã£o:** Plataforma no-code que transforma docs nÃ£o-estruturados em JSON via LLMs. Prompt Studio visual para definir schemas. Deploy como API ou ETL pipeline com um clique. Integra com n8n.
**Por que Ã© 5-10x melhor:**
- ğŸ¯ **Problema real:** Empresas gastam $50-200k/ano em data entry manual
- âš¡ **Velocidade:** De semanas de dev para horas no visual Prompt Studio
- ğŸš€ **Escala:** Um schema serve para milhares de variaÃ§Ãµes de documento
- ğŸ’¸ **Custo:** Self-hosted grÃ¡tis vs serviÃ§os de IDP (Intelligent Document Processing) a $25-100k/ano
**TAM:** $3B+ (intelligent document processing, 37% CAGR)
**Modelo de negÃ³cio:** Cloud edition com features enterprise (LLMChallenge, SSO, HITL)
**EsforÃ§o:** MÃ©dio â€” precisa orquestrar LLMs e storage, mas jÃ¡ tem Docker/cloud ready
**CombinaÃ§Ãµes:** Unstract + Docling (#89) = parsing perfeito + extraÃ§Ã£o estruturada. Unstract + n8n/Activepieces (#73) = automaÃ§Ã£o end-to-end de documentos

---

### [cocoindex-io/cocoindex](https://github.com/cocoindex-io/cocoindex) â­ 6.0k | âš¡ğŸ“ˆğŸ’¸
**Problema:** Pipelines de dados para AI (vector indexing, knowledge graphs) sÃ£o frÃ¡geis, lentos para atualizar, e exigem reprocessamento completo quando algo muda.
**SoluÃ§Ã£o:** Framework declarativo de transformaÃ§Ã£o de dados com core em Rust. Suporte nativo a processamento incremental â€” sÃ³ reprocessa o que mudou. Data lineage out-of-box.
**Por que Ã© 5-10x melhor:**
- âš¡ **Velocidade:** Core Rust = ordens de magnitude mais rÃ¡pido que Python puro. Incremental = atualiza em segundos vs reindexar tudo
- ğŸ“ˆ **Volume:** Escala para datasets massivos mantendo freshness
- ğŸ’¸ **Custo:** ~100 linhas de Python vs pipelines complexos com Airflow/dbt
**TAM:** $2B+ (data transformation/ETL for AI, mercado nascente mas explosivo)
**Modelo de negÃ³cio:** Cloud managed service, enterprise features
**EsforÃ§o:** MÃ©dio â€” requer Postgres, mas setup Ã© straightforward
**CombinaÃ§Ãµes:** CocoIndex + Docling (#89) + Graphiti (#91) = pipeline docâ†’transformaÃ§Ã£oâ†’knowledge graph com freshness automÃ¡tica

---

### [google/langextract](https://github.com/google/langextract) â­ 23.9k | ğŸ¯ğŸ’âš¡ğŸš€
**Problema:** Extrair informaÃ§Ã£o estruturada de texto livre (notas clÃ­nicas, contratos, relatÃ³rios) requer pipelines NER complexos, fine-tuning, ou regex frÃ¡geis. Empresas gastam meses construindo extractors customizados.
**SoluÃ§Ã£o:** Biblioteca Python do Google que usa LLMs para extrair dados estruturados com source grounding preciso (mapeia cada extraÃ§Ã£o ao texto original) + visualizaÃ§Ã£o HTML interativa. Funciona com few-shot examples, sem fine-tuning.
**Por que Ã© 5-10x melhor:**
- ğŸ¯ **Problema real:** Healthcare, legal, finance â€” todos precisam extrair dados de texto nÃ£o-estruturado
- ğŸ’ **Qualidade:** Source grounding elimina alucinaÃ§Ãµes â€” cada fact vem com highlight no texto original
- âš¡ **Velocidade:** Chunking otimizado + processamento paralelo supera "needle in haystack" de docs longos
- ğŸš€ **Escala:** De domÃ­nio especÃ­fico a qualquer domÃ­nio com few-shot examples â€” sem retreinamento
**TAM:** $5B+ (intelligent document processing + NLP extraction)
**Modelo de negÃ³cio:** SaaS de extraÃ§Ã£o vertical (healthcare, legal, finance), API metered, enterprise on-prem
**EsforÃ§o:** MÃ©dio â€” core library pronta, precisa wrapper SaaS + integrations
**CombinaÃ§Ãµes:** LangExtract + Docling (#89) = PDFâ†’textoâ†’extraÃ§Ã£o estruturada end-to-end. LangExtract + CocoIndex (#95) = pipeline incremental de extraÃ§Ã£o em larga escala

### [deepseek-ai/DeepSeek-OCR](https://github.com/deepseek-ai/DeepSeek-OCR) â­ 22.3k | ğŸ¯âš¡ğŸ’¸ğŸ“ˆ
**Problema:** OCR tradicional (Tesseract, ABBYY, AWS Textract) Ã© caro, lento em documentos complexos, e perde contexto semÃ¢ntico. OCR "inteligente" requer integraÃ§Ã£o de mÃºltiplas ferramentas.
**SoluÃ§Ã£o:** "Contexts Optical Compression" â€” modelo LLM-centric que investiga visÃ£o encoders de uma perspectiva centrada no LLM. ~2500 tokens/s em A100. DeepSeek-OCR2 jÃ¡ lanÃ§ado (Jan 2026). Suportado em vLLM upstream.
**Por que Ã© 5-10x melhor:**
- ğŸ¯ **Problema real:** Todo negÃ³cio digitaliza documentos â€” receitas, contratos, faturas
- âš¡ **Velocidade:** 2500 tokens/s throughput de produÃ§Ã£o
- ğŸ’¸ **Custo:** Open-source vs Textract/ABBYY pricing ($1.50+ per 1000 pages)
- ğŸ“ˆ **Volume:** Batch processing nativo, streaming output, concurrency otimizada
**TAM:** $15B+ (OCR/IDP market, um dos maiores de enterprise AI)
**Modelo de negÃ³cio:** Managed OCR API (pay-per-page), on-prem enterprise, vertical solutions (healthcare records, legal discovery)
**EsforÃ§o:** Alto â€” requer GPU infra, mas vLLM integration jÃ¡ resolve serving
**CombinaÃ§Ãµes:** DeepSeek-OCR + LangExtract (#128) = scanâ†’OCRâ†’extraÃ§Ã£o estruturada. DeepSeek-OCR + Unstract (#94) = document processing pipeline completo

---

### [VectifyAI/PageIndex](https://github.com/VectifyAI/PageIndex) â­ 12.0k | ğŸ¯ğŸ’âš¡

**O que faz:** RAG sem vetores â€” constrÃ³i Ã­ndice hierÃ¡rquico em Ã¡rvore de documentos e usa LLMs para reasoning-based retrieval. Inspirado no AlphaGo. AlcanÃ§ou **98.7% accuracy no FinanceBench** (vs ~70-80% de vector RAG). Chat platform, MCP server e API disponÃ­veis.

**Por que Ã© 5-10x melhor:**
- ğŸ¯ **Problema real:** Vector RAG falha em documentos profissionais longos (contratos, relatÃ³rios financeiros, papers mÃ©dicos) â€” similaridade â‰  relevÃ¢ncia
- ğŸ’ **98.7% accuracy** vs ~75% de vector RAG em benchmarks financeiros â€” salto qualitativo
- âš¡ **Sem chunking, sem embedding, sem vector DB** â€” pipeline drasticamente mais simples

**TAM:** $15B+ (enterprise search + document intelligence) â€” todo setor regulado (legal, financeiro, saÃºde)

**Modelo de negÃ³cio:** 
- SaaS: chat.pageindex.ai (jÃ¡ funcional)
- API/MCP: integraÃ§Ã£o em workflows existentes
- Enterprise: on-prem para setores regulados (compliance)
- Vertical solutions: FinTech, LegalTech, HealthTech

**EsforÃ§o:** Baixo â€” self-host com cÃ³digo open-source, cloud jÃ¡ disponÃ­vel

**CombinaÃ§Ãµes:** 
- PageIndex + DeepSeek-OCR (#161) = scanâ†’indexâ†’reasoning retrieval p/ documentos fÃ­sicos
- PageIndex + Motia (#166) = backend workflow com RAG frontier embutido
- PageIndex + LangExtract (#158) = extraÃ§Ã£o + retrieval reasoning = anÃ¡lise documental end-to-end
